package t1_10.t10_evolutionary_rejection_sampling;

import color.Color;
import compatibility.CompatibilityAnalyzer;
import dataset.DSFactory3D;
import dataset.painter.style.MarkerStyle;
import dataset.painter.style.enums.Marker;
import decisionsupport.operators.LNormOnSimplex;
import emo.interactive.iemod.IEMOD;
import emo.utils.decomposition.goal.GoalsFactory;
import emo.utils.decomposition.goal.IGoal;
import emo.utils.decomposition.similarity.ISimilarity;
import emo.utils.decomposition.similarity.lnorm.Euclidean;
import frame.Frame;
import interaction.feedbackprovider.dm.IDMFeedbackProvider;
import interaction.feedbackprovider.dm.artificial.value.ArtificialValueDM;
import interaction.reference.constructor.IReferenceSetConstructor;
import interaction.reference.constructor.RandomPairs;
import interaction.reference.validator.RequiredSpread;
import interaction.trigger.rules.IRule;
import interaction.trigger.rules.IterationInterval;
import model.IPreferenceModel;
import model.constructor.random.LNormGenerator;
import model.constructor.value.rs.ers.ERS;
import model.constructor.value.rs.ers.comparators.MostSimilarWithTieResolving;
import model.constructor.value.rs.ers.evolutionary.EvolutionaryModelConstructor;
import model.constructor.value.rs.ers.iterationslimit.ConstantZeroWhenNoFeedback;
import model.internals.value.scalarizing.LNorm;
import plot.Plot3D;
import plot.Plot3DFactory;
import problem.Problem;
import problem.moo.dtlz.DTLZBundle;
import random.IRandom;
import random.MersenneTwister64;
import runner.Runner;
import runner.enums.DisplayMode;
import scheme.enums.ColorFields;
import updater.DataUpdater;
import updater.DataUpdaterFactory;
import visualization.IVisualization;
import visualization.Visualization;
import visualization.updaters.sources.EASource;

/**
 * This brief tutorial showcases how to integrate the Evolutionary Rejection Sampling method
 * {@link model.constructor.value.rs.ers.ERS} with IEMO/D {@link emo.interactive.iemod.IEMOD}.
 *
 * @author MTomczyk
 */
public class Tutorial1a
{
    /**
     * Executes the tutorial.
     *
     * @param args not used
     */
    public static void main(String[] args)
    {
        IRandom R = new MersenneTwister64(0); // Prepare RNG
        // Get default problem bundle:
        // - DTLZ2 with 3 objectives and a default number of distance-related attributes (M + 20 - 1 = 22)
        // - SBX and PM operators are used with distribution indices of 20
        DTLZBundle problem = DTLZBundle.getBundle(Problem.DTLZ2, 3);

        // Generate L-infinity-norms using the Das and Dennis' method:
        IGoal[] goals = GoalsFactory.getLNormsDND(3, 15, Double.POSITIVE_INFINITY);
        int populationSize = goals.length; // the number of goals equals the population size

        // Quantifies similarity between the goals (Euclidean distance between weigh vectors):
        ISimilarity similarity = new Euclidean();

        // Neighborhood size for IEMO/D
        int neighborhoodSize = 10;

        // Rule for triggering the interactions (starting from 300th generation; every 100 generations; limit = 5 interactions):
        IRule rule = new IterationInterval(300, 100, 5);

        // Reference set constructor (constructs reference sets to be evaluated by the DM):
        // - Random pairs: the alternatives (objective vectors) should be no closer than 0.01 in the normalized space (using the Euclidean distance function)
        IReferenceSetConstructor referenceSetConstructor = new RandomPairs(new RequiredSpread(0.01d));

        // Example DM used to provide feedback on pairwise comparisons (Chebyshev function with equal weights):
        IDMFeedbackProvider DM = new ArtificialValueDM<>(
                new model.definitions.LNorm(new LNorm(new double[]{1.0d / 3.0d, 1.0d / 3.0d, 1.0d / 3.0d}, Double.POSITIVE_INFINITY)));

        // Initial preference model for learning (can be instantiated without initial internal models):
        IPreferenceModel<LNorm> model = new model.definitions.LNorm();

        // Instantiating ERS ------------------

        // Create params container (LNormGenerator is responsible for sampling initial random models):
        ERS.Params<LNorm> pERS = new ERS.Params<>(new LNormGenerator(3, Double.POSITIVE_INFINITY), 3);
        pERS._feasibleSamplesToGenerate = populationSize; // Population size = no. feasible samples to generate
        // Cannot go below the population size (if the no. compatible samples generated by ERS is smaller, inconsistency is triggered):
        pERS._inconsistencyThreshold = populationSize - 1;
        // Use constant no. iterations, i.e., improvement attempts (20000).
        // This implementation, however, returns 0 if preference learning is triggered when there is no feedback
        // (e.g., as a reaction to update in known objective space bounds):
        pERS._improvementAttemptsLimit = new ConstantZeroWhenNoFeedback(20000);
        // Limits data on k-nearest neighbors (k is limited to 3):
        pERS._kMostSimilarNeighbors = 3;

        // Use the following evolutionary model constructor:
        // - create models with alpha = Infinity (Chebyshev functions)
        // - use a tournament selection of size = 2
        // - use OnSimplexCombination crossover operator with std = 0.2
        // - use OnSimplexMutation operator with std = 0.2
        pERS._EMC = new EvolutionaryModelConstructor<>(new LNormOnSimplex(Double.POSITIVE_INFINITY, 0.2d, 0.2d), 2);

        // Comparator used: maximizes distance at 1-nn, in the case of a tie, checks 2-nn, and so on, until the tie is resolved.
        pERS._comparator = new MostSimilarWithTieResolving<>();

        // Quantifies similarity between generated L-norms (Euclidean distance between their weight vectors):
        pERS._similarity = new model.similarity.lnorm.Euclidean();
        // Use default compatibility analyzer:
        pERS._compatibilityAnalyzer = new CompatibilityAnalyzer();
        // Validate consistency of the already contained samples instead of starting from scratch in each sampling call:
        pERS._validateAlreadyExistingSamplesFirst = true;

        // Optionally the goals initially used in IEMO/D can serve as initial compatible models for ERS
        LNorm [] initialModels = new LNorm[goals.length];
        // Copy paste params (implementation-dependent):
        for (int i = 0; i < goals.length; i++)
            initialModels[i] = new LNorm(goals[i].getParams()[0].clone(),
                    goals[i].getParams()[1][0], null);
        pERS._initialModels = initialModels;

        // Create the ERS method:
        ERS<LNorm> ers = new ERS<>(pERS);

        // IMPORTANT NOTE: Most of the above fields are already set this way by default (check the code).
        // Another way of instantiating ERS (equivalent):
        //ers = ERSFactory.getDefaultForLNorms(populationSize, new ConstantZeroWhenNoFeedback(20000), 3, Double.POSITIVE_INFINITY,
        //        null, new LNormOnSimplex(Double.POSITIVE_INFINITY, 0.2d, 0.2d), 2,
        //        initialModels);

        // Instantiate IEMO/D (do not update OS dynamically, takes the normalizations from the problem bundle):
        IEMOD iemod = IEMOD.getIEMOD(false, false, R, goals, problem, similarity,
                neighborhoodSize, rule, referenceSetConstructor, DM, model, ers);

        // Prepare standard visualization:
        Plot3D plot3D = Plot3DFactory.getPlot("f1", "f2", "f3", 1.5d, 2.0f,
                scheme -> scheme._colors.put(ColorFields.PLOT_BACKGROUND, Color.WHITE));
        Frame frame = new Frame(plot3D, 0.5f);

        try
        {
            // Create standard data updater:
            DataUpdater DU = DataUpdaterFactory.getSimpleDataUpdater(frame.getModel().getPlotsWrapper(),
                    new EASource(iemod), DSFactory3D.getReferenceDS("Population",
                            new MarkerStyle(0.01f, color.gradient.Color.RED, Marker.SPHERE_MEDIUM_POLY_3D)));
            IVisualization visualization = new Visualization(frame, DU);

            // Create standard data updater coupled with the visualization module (populationSize = no. steady-state repeats).
            Runner.Params pR = new Runner.Params(iemod, populationSize, visualization);
            pR._displayMode = DisplayMode.FROM_THE_BEGINNING;
            Runner runner = new Runner(pR);

            // Init = generation 0
            runner.init();

            // Evolve for generations = 1,...,999
            for (int g = 1; g < 1000; g++)
            {
                System.out.println("Generation =  " + g);
                runner.executeSingleGeneration(g, null);
            }


        } catch (Exception e)
        {
            throw new RuntimeException(e);
        }
    }
}
